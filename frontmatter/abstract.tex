%
%  Time-stamp: "[abstract.tex] last modified by Scott Budge (scott) on 2017-01-10 (Tuesday, 10 January 2017) at 16:54:14 on goga.ece.usu.edu"
%
%  Info: $Id: abstract.tex 998 2017-03-21 16:44:33Z scott $   USU
%  Revision: $Rev: 998 $
% $LastChangedDate: 2017-03-21 10:44:33 -0600 (Tue, 21 Mar 2017) $
% $LastChangedBy: scott $
%

\begin{abstract}
% A space is needed before the text starts so that the first paragraph
% is indented properly.

Deep learning, a branch of machine learning has led to breakthrough and innovation in many areas such as computer vision, voice recognition and natural language processing. It is being used to guide all sorts of business decisions, both routine and high stakes because they promise to improve the quality and consistency of decision making. These techniques have been embraced in the regulated domain, where decisions like who gains access to healthcare and who gains access to critical opportunities depends on the output of the deep learning models. There is a growing perception that these learning algorithms from historical data can end up encoding human biases and prejudice they promised to alleviate. With the increasing complexity of deep learning models and their influence on the public domain, the critical need for understanding their inner-workings has increased. I discuss the societal implications of the black box models and the corresponding need to address the issue of transparency and fairness. I provide an overview of the deep learning visualization research, and the recent efforts to make deep learning models interpretable and explainable. This works uses explainable system approach together with image localization and visualization techniques to interpret the decision of a visual classification task that justifies the model decision using visual evidence, using the following methods: (i) Sensitivity analysis to show which part of the image attributed to the classification decision, and (ii) Activation graph visualizing intermediate outputs of the network to understand what the network has learned.


\end{abstract}


% Local Variables:
% TeX-master: "newhead"
% End:
