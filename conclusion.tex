%
%  This is an example of how a LaTeX thesis should be formatted.  This
%  document contains chapter 1 of the thesis.
%

\chapter{CONCLUSION}
%%%%%%%% This line gets rid of the page number on the first page of text
\thispagestyle{empty}
%%%%%%%%%%%%%

%INJECT[The first paragraph in the Discussion should summarize the Results. Most readers will read the Abstract, maybe the Introduction, and then the Discussion. Write the Discussion as if it were the first thing your readers saw.]

%INJECT[Then you need 2-3 paragraphs placing your results into a broader context. What does your work mean for the major question described in the Introduction? Also, how does your work relate to other work in the field? What specifically are the similarities and differences?]

%INJECT[Finally, and this is somewhat optional, you can write another paragraph that summarizes all your findings once more]

Research in deep learning has traditionally focused on new algorithms, mathematical models, improving quality and performance or the speed of the neural network model. I have studied and investigated a lateral research direction that touches upon the social implication of the automated decision-making systems, namely, we have contributed to furthering the understanding and transparency of the decision making implemented by a trained deep neural network. 

I proposed a visual exploration tool for interpreting a visual classifier that provides a visual explanation of the inference decision. The tool is targeted towards non-experts and helps broaden people's access to an interactive tool for deep learning. The visualization technique helps make an image recognition model more transparent by providing a visual explanation for its predictions. My prototype helped to answer two critical questions about model inference raised in our research hypothesis: (i) why did the network think this image contained a specific object (ii) where is the object located in the picture. I used the heatmap concept that allowed better intuition about what has been learned by the network.

Further, running deep learning application entirely client-side in the browser unlocked new opportunities to add rich interaction and user experience. From a user's perspective, there is no need to install any libraries or drivers. They can directly access the application in their browser. Finally, all the user data stays on the client-side local to the user device, and this helps to maintain as a privacy-preserving application.

In summary, I have presented a novel image explanation technique that justifies the class prediction of a visual classifier. This method could be a  stepping stone and serve as a foundation for a more robust model interpretability and explainable system. This work is a small contribution towards building a fair, transparent and explainable AI system

\section{Future Work}

I believe there are several opportunities to extend and enhance DeepViz as a visual exploration tool for the deep learning system. Future work will focus on improving DeepViz with new interaction capabilities, sophisticated visualization and better performance.

More generally, I see an immense opportunity for contributing to this new and rapidly growing body of research of deep learning visualization, with a focus on explainability and interpretability, whose impact spans a broad range of domain. For example, a visual analytics tool for interactive comparison of multiple models to assess transparency and fairness, visualize other models, e.g., auto-encoders, recurrent neural networks (RNNs) and generative adversarial networks (GANs), visualize deep networks in domains such as reinforcement learning, meta-learning and auto-ML.

Further, there are a number of directions for future work, such as creating new interpretable methods and visual representation for the components in deep learning models, develop rich visual interface with innovative interactions to discover and communicate more in-depth insight about one's model, a visual exploration tool that combines visual representation, new interaction technique, modern attribution and feature visualization.

There are several directions to make progress on the deep learning interpretability. I believe its time we address the issues of fairness, transparency and accountability in AI technologies, and make sure bias from the data doesn't get embedded in the systems we create.


\iffalse % ----- START THE CUT ---------

- A real-time exploratory analysis of the model during training process using interactive visualization. 
----There are a number of directions for future work on the deep learning interpretability
- Future work will focus on creating new interpretable methods and visual representation for the components in deep learning models.

- develop rich visual interface with new interaction technique to discover and communicate deeper insight about one's model

- a visual exploration tool that combines visual representation, new interaction technique, modern attribution and feature visualization.

- Future work will focus on improving DeepViz with more interaction capabilities, sophisticated visualization and better performance.

- I believe there are a number of opportunities to extend and enhance DeepViz as an visual exploration tool for deep learning models. Future work will focus on improving DeepViz with more interaction capabilities, sophisticated visualization and better performance.

There are a number of directions for future work on the deep learning interpretability. For example, interactive visual comparison of multiple models to assess their transparency and fairness. Exploratory analysis of the model training using interactive visualization. This would allow real-time analysis of the model during training process without having to wait for the entire training process to be completed. A visual analytics systems for neural network interpretation in advanced domains such as reinforcement learning, meta-learning and auto-ML.

Further research at the hybrid research areas of machine learning and AI, information visualization and visual analytics.

- This work is a small contribution towards building a fair, safe and explainable AI system

-Further research into deep learning visualization
-Further research for publishing in the Distill Research Journal
-Interactive visual comparison of multiple models 
-Visualize deep networks in domains such as reinforcement learning, meta-learning and auto-ML.
\fi % ---------- END THE CUT -----------