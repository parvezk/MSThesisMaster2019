\chapter{RESULTS}

\graphicspath{ {./results/} }
%%%%%%%% This line gets rid of page number on first page of text
\thispagestyle{empty}

%%%%%%%%%%%%%

In this section I provide qualitative research results and essential findings from prototype user testing spanning over multiple iterations over the course of thesis research and prototype development. 

\section{Visual Analysis}

The critical finding from the research highlights that the representations learned by the VGG16 model are highly receptive to visualization, in large part because they are representations of visual concepts. I used image localization technique and gradient computation to visualize relevance heatmap, which substantiates class attribution and feature activation graph highlighting learned representations. For both methods, I use the VGG16 model, a convolutional neural network model trained on the ImageNet database.

\section*{Sensitivity Analysis}

Figure 3.4 shows sample explanation which first declares a predicted class label followed by relevance heatmap. It acts as a visual evidence that justifies the prediction or desired class of interest. This method is useful to understand precisely which part of an image identified to belong to a specific class or category (class names known to VGG16), and thus allows localizing objects in images.

I submit the following image of a group of bee-eater sitting on a tree branch as an input image.

%Input image ~\ref{fig:myFig}.
\begin{figure}[htbp]
\centering
\includegraphics[width=0.80\textwidth]{images/colorful-group-of-birds-get-together_vkmuak6_e__F0000.png}
\caption{An image of colorful group of birds uploaded by the user}
\label{fig:myFig}
\end{figure}

%Class activation heatmap~\ref{fig:heatmap-1}.
\begin{figure}[htbp]
\centering
\includegraphics[width=0.50\textwidth]{images/heatmap-class-activations.png}
\caption{Image Receptivity}
\label{fig:heatmap-1}
\end{figure}

\section*{Feature Activation Graph}

This step helped to understand when fed with an input image, how successful layers of the network transformed the input image. It also helped get an idea of the meaning of the individual network filters.

My visualization technique helped to answer two important questions:

\begin{itemize}
\item  Why did the network think this image contained a bee-eater?
\item Where is the bee-eater located in the picture?
\end{itemize}

In particular, what is most exciting to note is that the head region of the fourth bird, which is the largest of all six birds are strongly activated: this is probably how the network can tell the difference between bee-eater and any other bird.

%\section{User Study}

\iffalse
\section{Visualization Outcome}
\section{Statistical Analysis}
\section{Visual Analysis}


\section{User Testing}
\section{Performance Testing}
\fi
