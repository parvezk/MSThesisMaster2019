\chapter{METHODOLOGIES}

\graphicspath{ {./methodologies/} }
%%%%%%%% This line gets rid of page number on first page of text
\thispagestyle{empty}

%%%%%%%%%%%%%

\section{Method Selection}

The methodologies section covers methods chosen to investigate the research problem. We begin this section by restating our research problem and underlying assumptions underpinning our study: interpreting and understanding deep neural networks using interactive visualization, to inspire human curiosity and learning among the non-technical audience, as well as broaden people's access to interactive tools for deep learning.

\subsection{Scientific Methods}

The primary method selected for the research process is the scientific method. We selected this method as it involves careful observation and empirical study. Science has been am empirical study of nature and scientific method has been the hallmark of several leading research in this inter-disciplinary field. Indeed, much like a child’s brain evolves to become a model builder and learn to learn, researchers in these field, over time, examined and pondered how to learn from nature by employing scientific method in their research process. 


Deep learning is essentially a method for machines to learn from data and classifying patterns that is loosely modeled on the way a biological brain learns to solve problems. This empirical method coupled with the detailed mathematical representation of the model and their numeric computation makes scientific method an ideal choice of method for this research. In this research, we use tools of scientific method for both performing experiments and raising application-agnostic questions of the inner working of the fundamental building blocks of the deep learning models, which ought to be examined with the tools of the scientific method to make sure we not only comprehend the effect, but also begin to understand the cause which is the raison d'\^{e}tre of science \cite{edsarx.1904.1092220190101}.

Although scientific method \cite{2016397} is more discussed and written about, it remains simple in its core concept: observe a phenomenon of interest, formulate a mathematical model, verify how the model accounts for past observations, and use it to predict variants of the phenomenon and future observations. And, following Popper, models shall be readily abandoned if falsified by observed data. However, falsifiability is often largely insufficient: models based on distinct and perhaps incompatible assumptions may often be concomitantly supported by a specific dataset. It is thus necessary to identify extensions to existing measurements and examine where conflicting models may deviate appreciably from each other, and thereby provide grounds for additional testing and falsification.

The scientific method consists of two stages: (i) formulating hypotheses, and the (ii) testing them \cite{2016397}. What differentiates this from other forms of methods is the second stage: subjecting hypotheses to empirical testing by ascertaining whether or not predictions derived from hypotheses are borne out in relevant observations and experiments. Hypotheses and assumptions are the initial stages of scientific inquiry because they incentivize seeking truth and a hint as to where to find it \cite{AYALA2016xi}.

The underlying principles of the scientific method \cite{gauch_jr_2012} are essential for evaluating the hypothesis, enhancing perspective, increasing productivity, and inspiring innovation. These principles include logic, probability, parsimony and hypothesis testing, as well as science's presuppositions, limitations, principles and bold claims of rationality and truth. Beyond such methodology, some practical issues are shared broadly across the sciences, such as implementing effective science education and relating the scientific enterprise to the humanities.

Additionally, we also employed other research methods to support our research processes, such as action as research, agile development and system design. The selection of a research methodology was dependent on the research question itself and how best it can be addressed: interpreting deep neural networks.

\subsection{Action Research}
Action Research is a research methodology driven by practical problems, emphasis participatory research, and develops practically useful solutions to a real-world problem iteratively. It offers a systematic and collaborative approach to conducting research that satisfies both the need for scientific rigor and promotion of sustainable social change and has been taken up by a variety of researchers in both academic and industrial settings \cite{Hayes:2011:RAR:1993060.1993065}.

Action Research is a comparative research on the effects and conditions of various forms of social action, and research effort leading to practical social action that utilizes a spiral of steps, each of which composed of a circle of planning, action, review and fact-finding about the result of the action\cite{Hayes:2011:RAR:1993060.1993065}. Action Research is not completely a method but instead its a a series of commitments and practice to observe and frame the problem through a series of principles for conducting various social inquiry.

In terms of other research approaches, Action Research differs in its ontological, epistemological, and methodological commitments \cite{edsjsr.312187519970101}. These underlying assumptions put the researcher and the association with research participants at the heart of the process of inquiry, covering all of the ways in which data are collected, analyzed, and reported and change is implemented.

Its also an interdisciplinary approach and explicitly democratic and collaborative. When conducing action research, the focus is to create research efforts with general people experiencing real problems in their everyday lives and not “for”, “about”, or “focused on” them \cite{Hayes:2011:RAR:1993060.1993065}. Thus, action research research focuses on localized solutions that is highly contextualized, with a greater emphasis on transferability than generalization. 

Action Research methodology is open-ended and iterative. The primary focus of AR is to implement action iteratively, in which action can include a policy or process change, the introduction of new technology, or other intervention, and significant measures of the work are both the quality of research results produced and the feasibility of the solution(s) that emerged. It utilizes cycles of inquiry that include planning, action, and reflection, in which the action being undertaken is continually designed and evaluated with research results emerging throughout these cycles. AR can incorporate multiple methods and welcomes the use of both qualitative and quantitative methods.

When it comes to cyclical rigor, Action Research is cyclical in nature, with an emphasis on problem formulation, design of an intervention, action (e.g., deploying the intervention), observation of the effects of the action, reflection, and then redefinition of the problem to start the cycle again. Visualizations of this process show action research as a cycle in circular format or a spiral with the circles progressing in some manner. The goal then is not to arrive at the solution to a given problem but to attempt to create a solution that is “better” in some way than previous solutions and helps the researchers and practitioners learn through the action they take

The research of interpretability in deep learning and machine learning has far reaching impact because they encourage transparency and accountability of the black box models. Action Research will be a useful method in our research as it emphasizes the knowledge produced in the context of the application. \cite{401014119781201}. It’s a distinct candidate research method when the objective is to explore theory concerning practice.

\section{Research Hypothesis}

With the growing complexity of the deep learning model and the critical need for understanding their inner working has increased. Visualization is a potentially a powerful techniques to fill such a critical need that can be used to see through the black box model and deconstruct it to understand what features the network has learned during inference.

While deep neural nets learn efficient representations and deliver superior performance, most users consider them as a ‘black-box.’ due to their opaque nature and incomprehensible working mechanism. As in most cases, they learn representation and patterns that is difficult to extract and present it in a human-readable form. While this is true for certain types of deep learning models, it is not entirely true for an image recognition model because they are representation of visual constructs and abstracts which can be deconstructed to see what shapes and patterns were detected by the model at successive layers \cite{Zeiler} and how does that correlate to the prediction class at the output.

Typically a neural network is provided with an instance, for example, an image or audio segment, and it computes transformation on this instance at successive layers until it finally produces a probability value for a prediction. Inside the network, each neuron at each layer detects a specific feature through training and multiple epochs. The information flowing through the neural network is a set of numerical weights parameters, and connections that provides no direct clues as to how the task is performed or what is the correlation between inputs and outputs. Further the parameter selection is random and adjusted iteratively throughout the training process. %Even when performing very similar tasks, the right choice of network parameters can vary widely, which include network structure, error bound, learning rate, optimization algorithm, depth and width of the hidden layers, and the data vector used, are often chosen in a trial-and-error process.

Our analysis of previous work suggest that deeper representation in a CNN capture high level abstracts or visual concepts \cite{Zeiler}. More importantly convolutional layers naturally retain the spatial information of the input data which is otherwise lost in the fully connected layers. Thus we expect the last convolutional layer to retain better features, which is balanced between spatial information and class semantics. The neurons in the last convolutional layer observe more and more the class specific information in the image, such as object parts. We can use gradient descent to compute the gradient of the activation output of the last convolutional layer in CNN to understand the importance of each neuron for a class of interest. We use relevance heatmap visualization to highlight the importance of each neuron (channel or filter) and its correlation to the prediction made by the model.

Building upon this assumption, we formulate setup our hypothesis as follows: Apply object detection and localization method for visualizing and explaining what part of an input image attributed most to the classification decision of the model. In other words, localization is useful to study which pixels in a given input has high activations or to what input neurons are most receptive to and how does that correlate to the class prediction.

% In deep learning visualization research, a large body of work is dedicated to visualizing particular neurons or neuron layers [1], [19]–[20][21][22][23][24] and learned parameters, our work chose to focus on collective output corresponding to the predicted class

\section{Design Goals}

The goal is to build an interactive visualization tool to interpret a visual classifier model and explain the predictions made by them using visual evidence.  The tool predicts a class label and then shows why the predicted label is appropriate for the image using relevance heatmap. This method is useful to highlight which part of the image is most relevant to the classification decision. The second method is activation graph that displays what features a neural network has learned and how the network builds their internal representation of  features detected by the network during the inference process. 

The tool serves as a visual explanation tool that enables interactive and explorable explanations of the model. It uses visualization technique that focuses on the class differential properties of the visual object and understand the inference made by a model.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{images/xai-1.eps}
\caption{Explanation Approach}
\label{fig:explanation-approach}
\end{figure}

The intent is to develop a set of utilities or toolkit as the first step towards building a robust explanation framework that can make any visual classifier more interpretable and explainable for the end user. The prototype is intended for people with a non-technical background to visually understand the decision of an image classifier. Our objective can be summarized mainly as (i) Provide visual explanation of the prediction made by a visual classifier to non-expert (ii) Education and communication for non-technical audience and (iii) broaden people's access to interactive tools for deep learning.

\section{Design Approach}

The problem of trust and transparency has been receiving more attention lately for nonlinear models. As a result, several methods have been developed to interpret what a deep neural network (DNN) has learned. A large section of work in DNN interpretability is dedicated to visualizing specific neurons or the layers. This work focuses on method that visualize the impact of particular regions of a given image for the prediction (predicted label) or the desired class of interest.

This section introduces two visualization techniques for explaining the prediction of an image classifier model.

\subsection{Image Receptiveness}

Image Receptiveness visualizes heatmap of the activation output corresponding to the predicted label. The process of explanation is summarized in the Fig 3.2.

This method is useful to interpret which part of an input image led the model to its final classification decision. It localizes the class discriminative region in the image by generating a heatmap superimposed on the input image. It highlights the discriminating region corresponding to the desired class clearly.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{images/method-schema-copy.eps}
\caption{Explanation Approach}
\label{fig:explanation-approach}
\end{figure}

For instance, when an image is submitted, the model predicts the class. The input image is correctly classified as "bee-eater". In order to understand why the model arrived at this decision, the tool generates a heatmap that visualizes the importance of each pixel in the input image for the prediction of that class. In this example, the bee-eater's beak and the neck are the basis for the model's decision. With the heatmap,user can verify that the model works as intended.

The tool uses localization to know what region in the image attributed most to the classification decision. This helps identify individual pixels in the input image that had the highest activations. Localization, in the context of CNN, is a task to localize objects in images using only whole image class labels. It indicates where the model has to look to make a specific decision. It identifies pixels which are pivotal for the prediction object.

In another instance, another example image is fed, the model predicts the class. the input image is misclassified as "hare", when the true label is cat. The user can see why it predicted a wrong label by inspecting the heatmap. Here, the model detected only the tail region and omitted other parts of the cat image, hence the feature extraction was not correct.

We use Class Activation Mapping approach (CAM) to obtain the localization map. We focus on the output of the last convolutional layer because it detects the high level features and differential to the predicted class. We compute the value of the activation output of the last convolutional layer. Then compute the gradient of the probability score of the class with respect to the logits or activation output of the last convolutional layer. This step helps capture the importance of the feature map for a targeted class. The gradient value is pooled within each filter by taking the global average mean. The resulting value is then multiplied with the activation output of the last convolutional layer for the weighted combination. The resulting value is averaged and all the filters are collapsed to create a heatmap vector. This is followed by ReLU activation in order to discard the negative values from the heatmap and normalize them. The heatmap vector is resized to match the size of the input image. An RGB colormap is applied to the heatmap vector to transform the 1-channel greyscale image into a color image. Then the color heatmap is overlaid on top of the input image to form the final output.

\subsection{Activation Graph}

Activation graph visualizes the intermediate activations of the network. It takes the values of the activation output of all the convolutional layer and produces a directed acyclic graph. The output of the layer is actually the sum of the output of the activation function of all the channels in that layer. The graph decomposes the activation output at every layer into a distribution of channels per layer.

Visualizing intermediate activations helps display the feature maps produced as output by various convolution and pooling layers in a network, given a certain input. This shows how an input is decomposed into the different filters learned by the network. These filters comprise 3 dimensions (width, height and depth), where each channel encodes relatively independent feature. Thus we visualize these feature maps for every channel as a 2D image in individual vertices.

The direction of the graph is from bottom to top corresponding to lower level to higher level. Each level represents a convolutional layer, where each vertices represents an individual channel. An edge connecting two vertices represents the weight between neurons in successive layers. User can explore the edges to discover what the network detects at each layer as it propagates the activation output forward. This step helps user understand when fed with an input image, how successive layers of the network transformed the input image. This also gives an idea of the meaning of the individual network filters.

Although VGG16 model has 18 such hidden layers with channels ranging from 64 to 512, we have limited the number of layers and channels in our view to only 8 in order to maintain optimum performance of the application given the rendering effort is expensive to render all channels.


\section{Technical Design}
The following segment provides an overview of the technical design and resources required for the successful development of the prototype. It provides a high-level overview of the components in scope, functionality, dataset and environmental setup.

\subsection{Client-side Neural Network}
Developing AI applications using modern deep learning framework is a non-trivial task. Normally these frameworks and libraries are leveraged by native applications that run on a native platform environment such as Linux, Windows, MacOS/iOS and Android. Thus most production-level libraries are developed for and written in Python, Java and C++. 

Developing machine learning application that is cross-platform and portable on multiple devices is not easy. The development of a native application is an intricate and time-consuming process. It is particularly complicated for mobile applications as the app vendors usually need to develop and maintain both iOS and Android version, in addition to the desktop application.

Compared to the native application, client-side applications can make the portability issue simpler for the cross-platform. The sample implementation of deep learning powered web application can be deployed on multiple platforms regardless of operating systems, hardware or device types.

Deep learning in the browser is at the experimental stage and recently a bunch of JavaScript-based deep learning framework has been introduced, making it possible to perform several deep learning tasks directly on the browser. Some of the supported features include model training, importing pre-trained models, transfer learning and inferences.

However, there is a debate on the feasibility and effectiveness of the web-based deep learning applications. One one hand, those who object think browsers are not primed for running deep learning tasks and its merely impractical due to the poor performance of client-side scripting and limitations imposed by the browsers. 

On the other hand, advocates think that the browser is an ideal platform for realizing client-side machine learning that allows highly rich interaction and improves personalization for end users. The benefits include but not limited to faster user interaction, preserving data privacy, lower back-end payload, reduced data transfer and performance latency of HTTP client-server communication.

\subsection{Supported Browser Features}
We analyzed the supported browser features for machine learning tasks and taken into consideration the factors that may affect the efficiency when building and deploying deep learning application on the web. One of them is the debugging capability to support model and data inspection when running deep learning tasks.

Further, in-browser deep learning allows users to use local data and then train the model directly in the browser, meaning there is no back-end end or server is necessary. 

\subsection{Model Selection}

As model selection is the centerpiece of the data science workflow, we evaluated a set of candidate pre-trained models by running a series of study and experiments. This also helped assess if the data collected for inference is suited to the problem of model selection. We taken into account the hyperparameter setting and other configuration details required to evaluate during the inference process if required. We tested the compatibility of the model with the available dataset. Based on our evaluation we selected VGG-16 as the primary model for the prototyping phase.

A schematic view of Visual Geometry Group 16 Model.~\ref{fig:CNN-2}.
\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{images/cnn-vgg16-1.png}
\caption{VGG16 hidden layers}
\label{fig:CNN-2}
\end{figure}

VGG-16 is based on convolutional neural network model proposed by the Visual Geometry Group from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition” \cite{2014arXiv1409.1556S}. The model achieves 92.7\% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014 competition. Ths list of hidden layers can be seen in the table \ref{table:vgg16-layer}. This model is used as the backbone network in our project.

\subsection{Dataset}

ImageNet is a massive database of image collection that consist of over 15 million labeled high-resolution images belonging to roughly 22,000 categories \cite{edsarx.1409.057520140101}. These images were downloaded from Google image search and labeled by humans using Amazon's Mechanical Turk crowd-sourcing tool in 2012. It took about two and half years to label all the images. 

The labeled dataset was first introduced in a competition called the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC). The competition used a subset of ImageNet with around 1000 images in each of 1000 categories. In total, there are 1.2 million training images, 50,000 validation images, and 150,000 testing images. To maintain consistency of resolution, images have been down-sampled to a fixed resolution of 256x256 dimensions.
    
\subsection{Framework Selection}

To develop client-side deep learning application, we surveyed several open source machine learning framework for the web such as TensorFlow, Keras, and WebDNN. Based on our assessment and feedback from the developer community, we opted for TensorFlow in Python and TensorFlow.js for the prototype development. We also use JavaScript ES6 and Node.js for server side processing and environmental setup.

We found TensorFlow.js as a better choice for training and inferring deep learning models on the browser. While several other open source JS platforms for machine learning have appeared in recent past, we found TensorFlow.js as feature-rich and well-documented when compared to other web libraries. Further, TensorFlow.js takes advantage of GPU processing power to accelerate deep learning tasks on browsers via WebGL \cite{Ma2019}, which is an important criteria for our tool that runs inference on a vision based model. WebGL is a back-end compute and a JavaScript API for rendering interactive 2D and 3D graphics within web browser without the use of additional plug-ins.

Since both client-side and server-side framework are part of the TensorFlow ecosystem, we can access APIs that are compatible with either ones. This also makes model conversion easier and allows for models to be ported between Python and JavaScript ecosystems \cite{Smilkov2019}.

\section{System Design}

As one of our goal for the prototype is to broaden people's access interactive tools for deep learning, and that the tool is targeted towards non-technical audience, DeepViz is a web-based interactive visualization tool that can be accessed from any modern web-browser. 

The development environment for the client side application is setup using JavaScript ecosystem and W3C web standards. DeepViz uses the web technologies: HTML, CSS, JavaScript ES6 and SVG. Node.js is used for back-end scripting for JavaScript ecosystem. For client-side visualization, we use SVG and D3.js for rendering vector graphics for the graph views. We also use the Lucid library for experimenting and testing feature visualizations in VGG16 model.

We leverage transpilers to transform code written in JavaScript ES6 into standard ES5 JavaScript that is executable in any browser. We also use bundling and tooling for local development and prototype deployment on the server.

\section{Environment Setup}

The development environment for the client side application is setup in Node.js environment. Its also used for tooling and bundling production deployment assets. For the back-end deep learning framework, we executed all our code on the workstation hosted on the virtual server provided by the NYU High Performance Computing services. 

%For the back-end deep learning framework, we executed all our code on an NVIDIA DGX, a workstation with 4 GPUs, with 16GB of RAM, 10 CPUs and 540GB of RAM.
