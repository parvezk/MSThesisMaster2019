%
%  This is an example of a bibliography file to be used in a LaTeX thesis.
%
%  Time-stamp: "[sample.bib] last modified by Scott Budge (scott) on 2016-07-28 (Thursday, 28 July 2016) at 08:59:52 on goga.ece.usu.edu"
%
%
% Remember to include the IEEEabrv.bib file while using this .bib file:
%
% \bibliography{IEEEabrv,sample}
%
% NOTE: It is HIGHLY recommended that you use the IEEE journal and magazine
%       title strings defined in IEEEabrv.bib.  They are standardized, will
%       prevent spelling errors, and are the ones used in IEEE journals.
%
%
%  Info: $Id: sample.bib 967 2016-07-28 15:33:29Z scott $   USU
%  Revision: $Rev: 967 $
% $LastChangedDate: 2016-07-28 09:33:29 -0600 (Thu, 28 Jul 2016) $
% $LastChangedBy: scott $
%

@article{featurevis,
author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
doi = {10.23915/distill.00007},
issn = {2476-0757},
journal = {Distill},
month = {nov},
number = {11},
pages = {e7},
title = {{Feature Visualization}},
url = {https://distill.pub/2017/feature-visualization},
volume = {2},
year = {2017}
}
@article{visrepdlhbcola,
title = {{Visualizing Representations: Deep Learning and Human Beings - colah's blog}},
url = {https://colah.github.io/posts/2015-01-Visualizing-Representations/}
}
@article{usingaitoahi,
author = {Carter, Shan and Nielsen, Michael},
doi = {10.23915/distill.00009},
issn = {2476-0757},
journal = {Distill},
month = {dec},
number = {12},
pages = {e9},
title = {{Using Artificial Intelligence to Augment Human Intelligence}},
url = {https://distill.pub/2017/aia},
volume = {2},
year = {2017}
}
@article{Olah2018,
author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
doi = {10.23915/distill.00010},
issn = {2476-0757},
journal = {Distill},
month = {mar},
number = {3},
pages = {e10},
title = {{The Building Blocks of Interpretability}},
url = {https://distill.pub/2018/building-blocks},
volume = {3},
year = {2018}
}
@article{diffimageparam,
author = {Mordvintsev, Alexander and Pezzotti, Nicola and Schubert, Ludwig and Olah, Chris},
doi = {10.23915/distill.00012},
issn = {2476-0757},
journal = {Distill},
month = {jul},
number = {7},
pages = {e12},
title = {{Differentiable Image Parameterizations}},
url = {https://distill.pub/2018/differentiable-parameterizations},
volume = {3},
year = {2018}
}

Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Wongsuphasawat2018,
abstract = {},
author = {Wongsuphasawat, Kanit and Smilkov, Daniel and Wexler, James and Wilson, Jimbo and Man{\'{e}}, Man´ and Fritz, Doug and Krishnan, Dilip and V{\'{i}}, Fernanda B and Wattenberg, Martin},
doi = {10.1109/TVCG.2017.2744878},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Wongsuphasawat et al. - 2018 - Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow.pdf:pdf},
issn = {1077-2626},
journal = {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
keywords = {Clustered Graph,Dataflow Graph,Graph Visualization,Index Terms-Neural Network},
number = {1},
title = {{Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow}},
url = {http://www.ieee.org/publications{\_}standards/publications/rights/index.html},
volume = {24},
year = {2018}
}

@article{Polson2018,
abstract = {},
archivePrefix = {arXiv},
arxivId = {1807.07987},
author = {Polson, Nicholas G. and Sokolov, Vadim O.},
doi = {10.1038/nature14539},
eprint = {1807.07987},
file = {:DRIVE/HUB/Research-Papers/Downloaded/Deep learning - Yann LeCun, Yoshua Bengio, Geoffrey Hinton4.pdf:pdf},
isbn = {9781450358095},
issn = {14764687},
journal = {Nature},
month = {jul},
number = {7553},
pages = {436--444},
pmid = {10463930},
title = {{Deep Learning}},
url = {http://arxiv.org/abs/1807.07987},
volume = {521},
year = {2018}
}
@techreport{Kahng2018,
abstract = {Fig. 1. ACTIVIS integrates several coordinated views to support exploration of complex deep neural network models, at both instance-and subset-level. },
archivePrefix = {arXiv},
arxivId = {arXiv:1704.01942v2},
author = {Kahng, Minsuk and Andrews, Pierre Y and Kalro, Aditya and {Horng Chau}, Duen},
eprint = {arXiv:1704.01942v2},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Kahng et al. - Unknown - ACTIVIS Visual Exploration of Industry-Scale Deep Neural Network Models.pdf:pdf},
keywords = {Index Terms-Visual analytics,deep learning,information visualization,machine learning},
title = {{ACTIVIS: Visual Exploration of Industry-Scale Deep Neural Network Models}},
url = {http://cogcomp.cs.illinois.edu/Data/QA/QC/},
year = {2018}
}
@article{Tzeng2005,
abstract = {},
author = {Tzeng, Fan-Yin and Ma, Kwan-Liu},
doi = {10.1109/VISUAL.2005.1532820},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Tzeng, Ma - 2005 - Opening the Black Box — Data Driven Visualization of Neural Networks.pdf:pdf},
isbn = {0780394623},
journal = {Proceedings ofIEEE Visualization'05},
keywords = {artificial neural network,backpropagation,black box opening,classification task,data driven visualization,data visualisation,human nervous system,machine learning tool,neural nets,problem solving},
pages = {383--390},
title = {{Opening the Black Box — Data Driven Visualization of Neural Networks}},
year = {2005}
}
@article{Hohman2018,
abstract = {},
archivePrefix = {arXiv},
arxivId = {1801.06889},
author = {Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
eprint = {1801.06889},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Hohman et al. - 2018 - Visual Analytics in Deep Learning An Interrogative Survey for the Next Frontiers.pdf:pdf},
month = {jan},
title = {{Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers}},
url = {http://arxiv.org/abs/1801.06889},
year = {2018}
}
@article{Pezzotti2018,
abstract = {},
author = {Pezzotti, Nicola and H{\"{o}}llt, Thomas and {Van Gemert}, Jan and Lelieveldt, Boudewijn P.F. and Eisemann, Elmar and Vilanova, Anna},
doi = {10.1109/TVCG.2017.2744358},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Pezzotti et al. - 2018 - DeepEyes Progressive Visual Analytics for Designing Deep Neural Networks.pdf:pdf},
isbn = {0390-6078},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Progressive visual analytics,deep neural networks,machine learning},
number = {1},
pages = {98--108},
pmid = {21330322},
title = {{DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks}},
volume = {24},
year = {2018}
}
@article{Choo2018,
abstract = {},
archivePrefix = {arXiv},
arxivId = {1804.02527},
author = {Choo, Jaegul and Liu, Shixia},
eprint = {1804.02527},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Choo, Liu - 2018 - Visual Analytics for Explainable Deep Learning.pdf:pdf},
month = {apr},
title = {{Visual Analytics for Explainable Deep Learning}},
url = {http://arxiv.org/abs/1804.02527},
year = {2018}
}
@article{visdnncv,
abstract = {},
author = {Seifert, Christin and Aamir, Aisha and Balagopalan, Aparna and Jain, Dhruv and Sharma, Abhinav and Grottel, Sebastian and Gumhold, Stefan and Seifert, C and Aamir, • A and Balagopalan, • A and Jain, • D and Sharma, • A and Grottel, • S and Gumhold, • S},
doi = {10.1007/978-3-319-54024-5_6},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Seifert et al. - 2017 - Transparent Data Mining for Big and Small Data(2).pdf:pdf},
journal = {Studies in Big Data},
title = {{Visualizations of Deep Neural Networks in Computer Vision: A Survey}},
url = {https://link-springer-com.proxy.library.nyu.edu/content/pdf/10.1007{\%}2F978-3-319-54024-5{\_}6.pdf},
volume = {32},
year = {2017}
}

Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{darksecretaimittr,
title = {{The Dark Secret at the Heart of AI - MIT Technology Review}},
url = {https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/},
urldate = {2018-11-04}
}
@article{dlmittr,
author = {عيسى, البجحان},
file = {:DRIVE/HUB/Research-Papers/Downloaded/Deep Learning With massive amounts of computational power.pdf:pdf},
title = {{Deep Learning - MIT Technology Review}}
}
@techreport{dlacc,
abstract = {},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Marcus et al. - Unknown - Deep Learning A Critical Appraisal.pdf:pdf},
title = {{Deep Learning: A Critical Appraisal}},
url = {http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-}
}
@misc{intrpropnn,
archivePrefix = {arXiv},
arxivId = {1312.6199},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
eprint = {1312.6199},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Szegedy et al. - 2013 - Intriguing properties of neural networks(2).pdf:pdf},
title = {{Intriguing properties of neural networks}},
year = {2013}
}
@techreport{visunfcnn,
abstract = {},
author = {Zeiler, Matthew D and Fergus, Rob},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Zeiler, Fergus - 2014 - LNCS 8689 - Visualizing and Understanding Convolutional Networks.pdf:pdf},
title = {{LNCS 8689 - Visualizing and Understanding Convolutional Networks}},
url = {https://link-springer-com.proxy.library.nyu.edu/content/pdf/10.1007{\%}2F978-3-319-10590-1{\_}53.pdf},
year = {2014}
}
@article{visdrasla,
author = {Sacha, Dominik and Zhang, Leishi and Sedlmair, Michael and Lee, John A. and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C. and Keim, Daniel A.},
doi = {10.1109/TVCG.2016.2598495},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Sacha et al. - 2017 - Visual Interaction with Dimensionality Reduction A Structured Literature Analysis.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {jan},
number = {1},
pages = {241--250},
title = {{Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis}},
url = {http://ieeexplore.ieee.org/document/7536217/},
volume = {23},
year = {2017}
}

@book{molnar,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  publisher  = {https://christophm.github.io/interpretable-ml-book/},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

@book{taylor2006methods,
  title={Methods and procedures for the verification and validation of artificial neural networks},
  author={Taylor, Brian J},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@article{hansen2011visual,
  title={Visual Interpretation of Kernel-based prediction models},
  author={Hansen, Katja and Baehrens, David and Schroeter, Timon and Rupp, Matthias and M{\"u}ller, Klaus-Robert},
  journal={Molecular Informatics},
  volume={30},
  number={9},
  pages={817--826},
  year={2011},
  publisher={Wiley Online Library}
}


@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science}
}

@article{bojarski2017explaining,
  title={Explaining how a deep neural network trained with end-to-end learning steers a car},
  author={Bojarski, Mariusz and Yeres, Philip and Choromanska, Anna and Choromanski, Krzysztof and Firner, Bernhard and Jackel, Lawrence and Muller, Urs},
  journal={arXiv preprint arXiv:1704.07911},
  year={2017}
}

@inproceedings{Caruana:2015:IMH:2783258.2788613,
 author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
 title = {Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission},
 booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '15},
 year = {2015},
 isbn = {978-1-4503-3664-2},
 location = {Sydney, NSW, Australia},
 pages = {1721--1730},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2783258.2788613},
 doi = {10.1145/2783258.2788613},
 acmid = {2788613},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {additive models, classification, healthcare, intelligibility, interaction detection, logistic regression, risk prediction},
} 
[download]

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{karpathy2014large,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1725--1732},
  year={2014}
}

@inproceedings{graves2013speech,
  title={Speech recognition with deep recurrent neural networks},
  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={6645--6649},
  year={2013},
  organization={IEEE}
}

@article{mohamed2012acoustic,
  title={Acoustic modeling using deep belief networks},
  author={Mohamed, Abdel-rahman and Dahl, George E and Hinton, Geoffrey},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={20},
  number={1},
  pages={14--22},
  year={2012},
  publisher={IEEE}
}

@misc{bengio2003neural,
  title={A neural probabilistic language model. journal of machine learning research, Vol. 3, No},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  year={2003},
  publisher={Feb}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}

@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model},
  author={Mikolov, Tom{\'a}{\v{s}} and Karafi{\'a}t, Martin and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Eleventh annual conference of the international speech communication association},
  year={2010}
}

@book{sammut2011encyclopedia,
  title={Encyclopedia of machine learning},
  author={Sammut, Claude and Webb, Geoffrey I},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@article{Yosinski2015,
journal = {Yosinski2015},
archivePrefix = {arXiv},
arxivId = {1506.06579},
author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
eprint = {1506.06579},
file = {},
mendeley-groups = {1.PRIORITY},
month = {jun},
title = {{Understanding Neural Networks Through Deep Visualization}},
url = {https://arxiv.org/abs/1506.06579},
year = {2015}
}

@book{minsky2017perceptrons,
  title={Perceptrons: An introduction to computational geometry},
  author={Minsky, Marvin and Papert, Seymour A},
  year={2017},
  publisher={MIT press}
}

@book{efron2016computer,
  title={Computer age statistical inference},
  author={Efron, Bradley and Hastie, Trevor},
  volume={5},
  year={2016},
  publisher={Cambridge University Press}
}

@Book{sejnowski2018deep,
  title={The deep learning revolution},
  author={Sejnowski, Terrence J},
  year={2018},
  publisher={MIT Press}
}

@article{Knight2017,
author = {Knight, W},
file = {:DRIVE/HUB/Research-Papers/Downloaded/The Dark Secret at the Heart of AI - MIT Technology Review.pdf:pdf},
mendeley-groups = {1.XAI},
pages = {1--31},
title = {{The Dark Secret at the Heart of AI - MIT Technology Review}},
year = {2017}
}

@techreport{dlvwz,
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - 2018 - Deep Learning Visualization.pdf:pdf},
mendeley-groups = {1.PRIORITY},
title = {{Deep Learning Visualization}},
url = {https://search-proquest-com.proxy.library.nyu.edu/pqdtglobal/docview/2130944962/DDFF00D433AE4BBFPQ/3?accountid=12768},
year = {2018}
}

@techreport{Samek,
abstract = {},
archivePrefix = {arXiv},
arxivId = {1708.08296v1},
author = {Samek, Wojciech and Wiegand, Thomas and M{\"{u}}ller, Klaus-Robert},
eprint = {1708.08296v1},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Samek, Wiegand, M{\"{u}}ller - Unknown - EXPLAINABLE ARTIFICIAL INTELLIGENCE UNDERSTANDING, VISUALIZING AND INTERPRETING DEEP LEARNING MODELS.pdf:pdf},
mendeley-groups = {1.XAI},
title = {{EXPLAINABLE ARTIFICIAL INTELLIGENCE: UNDERSTANDING, VISUALIZING AND INTERPRETING DEEP LEARNING MODELS}},
url = {https://arxiv.org/pdf/1708.08296.pdf}
}

@book{gauch_jr_2012,
place={Cambridge}, title={Scientific Method in Brief}, DOI={10.1017/CBO9781139095082}, publisher={Cambridge University Press}, author={Gauch, Jr, Hugh G.}, year={2012}}


@incollection{2016397,
	Booktitle = {Evolution, Explanation, Ethics and Aesthetics},
	Doi = {https://doi.org/10.1016/B978-0-12-803693-8.18001-6},
	Editor = {Francisco J. Ayala},
	Isbn = {978-0-12-803693-8},
	Pages = {397 - 408},
	Publisher = {Academic Press},
	Title = {Index},
	Url = {http://www.sciencedirect.com/science/article/pii/B9780128036938180016},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/B9780128036938180016},
	Bdsk-Url-2 = {https://doi.org/10.1016/B978-0-12-803693-8.18001-6}}

@article{edsarx.1904.1092220190101,
Abstract = {In the quest to align deep learning with the sciences to address calls for rigor, safety, and interpretability in machine learning systems, this contribution identifies key missing pieces: the stages of hypothesis formulation and testing, as well as statistical and systematic uncertainty estimation -- core tenets of the scientific method. This position paper discusses the ways in which contemporary science is conducted in other domains and identifies potentially useful practices. We present a case study from physics and describe how this field has promoted rigor through specific methodological practices, and provide recommendations on how machine learning researchers can adopt these practices into the research ecosystem. We argue that both domain-driven experiments and application-agnostic questions of the inner workings of fundamental building blocks of machine learning models ought to be examined with the tools of the scientific method, to ensure we not only understand effect, but a},
Author = {Forde, Jessica Zosa and Paganini, Michela},
Keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
Title = {The Scientific Method in the Science of Machine Learning.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1904.10922&site=eds-live},
Year = {2019},
}

@inbook{Manaswi2018,
	Abstract = {A convolutional neural network (CNN) is a deep, feed-forward artificial neural network in which the neural network preserves the hierarchical structure by learning internal feature representations and generalizing the features in the common image problems such as object recognition and other computer vision problems. It is not restricted to images; it also receives state-of-the-art results in natural language processing problems and speech recognition.},
	Address = {Berkeley, CA},
	Author = {Manaswi, Navin Kumar},
	Booktitle = {Deep Learning with Applications Using Python : Chatbots and Face, Object, and Speech Recognition With TensorFlow and Keras},
	Doi = {10.1007/978-1-4842-3516-4_6},
	Isbn = {978-1-4842-3516-4},
	Pages = {91--96},
	Publisher = {Apress},
	Title = {Convolutional Neural Networks},
	Url = {https://doi.org/10.1007/978-1-4842-3516-4_6},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-1-4842-3516-4_6}}


@incollection{AYALA2016xi,
	Author = {Francisco J. Ayala},
	Booktitle = {Evolution, Explanation, Ethics and Aesthetics},
	Doi = {https://doi.org/10.1016/B978-0-12-803693-8.05001-5},
	Editor = {Francisco J. Ayala},
	Isbn = {978-0-12-803693-8},
	Pages = {xi - xiii},
	Publisher = {Academic Press},
	Title = {Preface},
	Url = {http://www.sciencedirect.com/science/article/pii/B9780128036938050015},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/B9780128036938050015},
	Bdsk-Url-2 = {https://doi.org/10.1016/B978-0-12-803693-8.05001-5}}

@article{Hayes:2011:RAR:1993060.1993065,
 author = {Hayes, Gillian R.},
 title = {The Relationship of Action Research to Human-computer Interaction},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {July 2011},
 volume = {18},
 number = {3},
 month = aug,
 year = {2011},
 issn = {1073-0516},
 pages = {15:1--15:20},
 articleno = {15},
 numpages = {20},
 url = {http://doi.acm.org/10.1145/1993060.1993065},
 doi = {10.1145/1993060.1993065},
 acmid = {1993065},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Action research, collaborative inquiry},
}

@techreport{ainow2016report,
abstract = {},
author = {Kate Crawford, Meredith Whitaker},
institution = {ainow, NYU},
file = {},
mendeley-groups = {2.XAI-1},
title = {{AI NOW 2016 - The AI Now Report The Social and Economic Implications of Artificial Intelligence Technologies in the Near-Term AI Now Overview}},
url = {https://artificialintelligencenow.com/schedule/workshop/attendees},
year = {2016}
}

@article{Solon2017,
author = {Solon, Society and Labor, Summary Introduction and Ai, Task and Inequality, Work and Where, Redistribution and The, From and Recent, Diverse and Population, Bias and Corporate, Power and Ai, Entanglements},
file = {:MYDRIVE/HUB/AI$\backslash$:ML$\backslash$:Data-Science/AI Ethics {\&} Bias/AI{\_}Now{\_}2017{\_}Report.pdf:pdf},
mendeley-groups = {2.XAI-1},
title = {{AI Now 2017 Report}},
year = {2017}
}

@article{12344610220170601,
Abstract = {},
Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
ISSN = {00010782},
Journal = {Communications of the ACM},
Keywords = {Artificial neural networks, Computer architecture, Image databases, Signal convolution, Computer vision},
Number = {6},
Pages = {84 - 90},
Title = {ImageNet Classification with Deep Convolutional Neural Networks.},
Volume = {60},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=123446102&site=eds-live},
Year = {2017},
}

@article{edseee.690947520140101,
Abstract = {},
Author={},
ISSN = {978-1-4799-5118-5},
Journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition, Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
Keywords = {Computing and Processing, Proposals, Feature extraction, Training, Visualization, Object detection, Vectors, Support vector machines},
Pages = {580},
Title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edseee&AN=edseee.6909475&site=eds-live},
Year = {2014},
}

@article{edsarx.1411.455520140101,
Abstract = {},
Author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
Keywords = {Computer Science - Computer Vision and Pattern Recognition},
Title = {Show and Tell: A Neural Image Caption Generator.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1411.4555&site=eds-live},
Year = {2014},
}

@article{edsarx.1411.495220140101,
Abstract = {},
Author = {Fang, Hao and Gupta, Saurabh and Iandola, Forrest and Srivastava, Rupesh and Deng, Li and Dollár, Piotr and Gao, Jianfeng and He, Xiaodong and Mitchell, Margaret and Platt, John C. and Zitnick, C. Lawrence and Zweig, Geoffrey},
Keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
Title = {From Captions to Visual Concepts and Back.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1411.4952&site=eds-live},
Year = {2014},
}

@article{edseee.778086320160101,
Abstract = {We introduce the dense captioning task, which requires a computer vis},
ISSN = {978-1-4673-8851-1},
Journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on},
Keywords = {Computing and Processing, Proposals, Shape, Tensile stress, Object detection, Visualization, Interpolation, Predictive models},
Pages = {4565},
Title = {DenseCap: Fully Convolutional Localization Networks for Dense Captioning.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edseee&AN=edseee.7780863&site=eds-live},
Year = {2016},
}

@article{edseee.741063620150101,
Abstract = {},
ISSN = {978-1-4673-8391-2},
Journal = {2015 IEEE International Conference on Computer Vision (ICCV), Computer Vision (ICCV), 2015 IEEE International Conference on, Computer Vision, IEEE International Conference on},
Keywords = {Computing and Processing, Visualization, Image color analysis, Knowledge discovery, Cognition, Measurement, Glass},
Pages = {2425},
Title = {VQA: Visual Question Answering.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edseee&AN=edseee.7410636&site=eds-live},
Year = {2015},
}

@article{edsarx.1505.0561220150101,
Abstract = {},
Keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language, Computer Science - Learning, I.2.6, I.2.7, I.2.10},
Title = {Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1505.05612&site=eds-live},
Year = {2015},
}

@article{edseee.741036620150101,
Abstract = {},
ISSN = {978-1-4673-8391-2},
Journal = {2015 IEEE International Conference on Computer Vision (ICCV), Computer Vision (ICCV), 2015 IEEE International Conference on, Computer Vision, IEEE International Conference on},
Keywords = {Computing and Processing, Visualization, Knowledge discovery, Recurrent neural networks, Natural languages, Computer architecture, Semantics},
Pages = {1},
Title = {Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edseee&AN=edseee.7410366&site=eds-live},
Year = {2015},
}

@article{Hagras2018,
abstract = {},
author = {Hagras, Hani},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Hagras - 2018 - Cover Feature Future of Ai.pdf:pdf},
mendeley-groups = {2.XAI-1},
title = {{Toward Human- Understandable, Explainable AI}},
year = {2018}
}

@article{Ma2019,
abstract = {Recently, several JavaScript-based deep learning frameworks have emerged, making it possible to perform deep learning tasks directly on browsers. However, there are debates on the necessity and efficiency of deep learning on browsers. On one hand, advocators think that given the cross-platform feature, the browser is an ideal platform to realize client-side machine learning, which can preserve the data privacy, increase the user personalization, as well as lower the backend workload. On the other hand, objectors think that deep learning on browsers is impractical due to the poor performance of JavaScript and constraints imposed by browsers. To make a first step towards consensus, in this paper, we conduct an empirical study of deep learning on browsers. We first survey 7 most popular JavaScript-based deep learning frameworks, investigating to what extent deep learning tasks have been supported so far. Then we investigate the performance of different frameworks when running different deep learning tasks. Finally, we dig out the performance gap between deep learning on browsers and on native platform by comparing the performance of TensorFlow.js and TensorFlow in Python. Our findings could help to improve the efficiency of deep learning on browsers.},
archivePrefix = {arXiv},
arxivId = {1901.09388},
author = {Ma, Yun and Xiang, Dongwei and Zheng, Shuyu and Tian, Deyu and Liu, Xuanzhe},
eprint = {1901.09388},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Ma et al. - 2019 - Moving Deep Learning into Web Browser How Far Can We Go.pdf:pdf},
mendeley-groups = {1.PRIORITY-1},
month = {jan},
title = {{Moving Deep Learning into Web Browser: How Far Can We Go?}},
url = {http://arxiv.org/abs/1901.09388},
year = {2019}
}


@article{Smilkov2019,
abstract = {TensorFlow.js is a library for building and executing machine learning algorithms in JavaScript. TensorFlow.js models run in a web browser and in the Node.js environment. The library is part of the TensorFlow ecosystem, providing a set of APIs that are compatible with those in Python, allowing models to be ported between the Python and JavaScript ecosystems. TensorFlow.js has empowered a new set of developers from the extensive JavaScript community to build and deploy machine learning models and enabled new classes of on-device computation. This paper describes the design, API, and implementation of TensorFlow.js, and highlights some of the impactful use cases.},
archivePrefix = {arXiv},
arxivId = {1901.05350},
author = {Smilkov, Daniel and Thorat, Nikhil and Assogba, Yannick and Yuan, Ann and Kreeger, Nick and Yu, Ping and Zhang, Kangyi and Cai, Shanqing and Nielsen, Eric and Soergel, David and Bileschi, Stan and Terry, Michael and Nicholson, Charles and Gupta, Sandeep N. and Sirajuddin, Sarah and Sculley, D. and Monga, Rajat and Corrado, Greg and Viegas, Fernanda B. and Wattenberg, Martin},
eprint = {1901.05350},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Smilkov et al. - 2019 - TensorFlow.js Machine Learning for the Web and Beyond.pdf:pdf},
keywords = {tfmlwebandbeyond},
mendeley-groups = {1.PRIORITY-1},
month = {jan},
title = {{TensorFlow.js: Machine Learning for the Web and Beyond}},
url = {http://arxiv.org/abs/1901.05350},
year = {2019}
}

@article{edsarx.1409.057520140101,
Abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
Author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
Keywords = {Computer Science - Computer Vision and Pattern Recognition, I.4.8, I.5.2},
Title = {ImageNet Large Scale Visual Recognition Challenge.},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1409.0575&site=eds-live},
Year = {2014},
}

@ARTICLE{2014arXiv1409.1556S,
       author = {{Simonyan}, Karen and {Zisserman}, Andrew},
        title = "{Very Deep Convolutional Networks for Large-Scale Image Recognition}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = "2014",
        month = "Sep",
          eid = {arXiv:1409.1556},
        pages = {arXiv:1409.1556},
archivePrefix = {arXiv},
       eprint = {1409.1556},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014arXiv1409.1556S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{401014119781201,
Abstract = {This article describes the deficiencies of positivist science for generating knowledge for use in solving problems that members of organizations face. Action research is introduced as a method for correcting these deficiencies. When action research is tested against the criteria of positivist science, action research is found not to meet its critical tests. The appropriateness of positivist science is questioned as a basis for judging the scientific merits of action research. Action research can base its legitimacy as science in philosophical traditions that are different from those which legitimate positivist science. Criteria and methods of science appropriate to action research are offered. [ABSTRACT FROM AUTHOR]},
Author = {Susman, Gerald I. and Evered, Roger D.},
ISSN = {00018392},
Journal = {Administrative Science Quarterly},
Keywords = {Problem solving, Organizational sociology, Action research, Logical positivism, Methodology, Research evaluation},
Number = {4},
Pages = {582 - 603},
Title = {An Assessment of the Scientific Merits of Action Research.},
Volume = {23},
URL = {http://proxy.library.nyu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=4010141&site=eds-live},
Year = {1978},
}

@article{Lipton2018,
author = {Lipton and C., Zachary},
doi = {10.1145/3236386.3241340},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Lipton, C. - 2018 - The Mythos of Model Interpretability.pdf:pdf},
issn = {1542-7730},
journal = {Queue},
mendeley-groups = {2.XAI-1},
number = {3},
pages = {30},
publisher = {ACM},
title = {{The Mythos of Model Interpretability}},
url = {https://dl.acm.org/citation.cfm?id=3241340},
volume = {16},
year = {2018}
}

@article{Abdul,
abstract = {Advances in artificial intelligence, sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives, it becomes increasingly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explainable systems, as well as 12,412 citing papers. Using topic modeling, co-occurrence and network analysis, we mapped the research space from diverse domains, such as algorithmic accountability , interpretable machine learning, context-awareness, cognitive psychology, and software learnability. We reveal fading and burgeoning trends in explainable systems, and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results, we propose several implications and directions for future research towards this goal.},
author = {Abdul, Ashraf and Vermeulen, Jo and Wang, Danding and Lim, Brian Y and Kankanhalli, Mohan},
doi = {10.1145/3173574.3174156},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Abdul et al. - Unknown - Trends and Trajectories for Explainable, Accountable and Intelligible Systems An HCI Research Agenda.pdf:pdf},
isbn = {9781450356206},
keywords = {Author's kit,Conference Publications,Guides,instructions},
mendeley-groups = {2.XAI-1},
title = {{Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda}},
url = {https://doi.org/10.1145/3173574.3174156}
}

@techreport{Gunning,
author = {Gunning, David},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Gunning - Unknown - Explainable Artificial Intelligence (XAI).pdf:pdf},
mendeley-groups = {2.XAI-1},
title = {{Explainable Artificial Intelligence (XAI)}},
url = {https://www.cc.gatech.edu/{~}alanwags/DLAI2016/(Gunning) IJCAI-16 DLAI WS.pdf}
}

@techreport{Gunning2,
abstract = {perceive rich, complex and subtle information learn within an environment reason to plan and to decide abstract to create new meanings},
author = {Gunning, David},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Gunning - Unknown - Explainable Artificial Intelligence Research at DARPA.pdf:pdf},
mendeley-groups = {2.XAI-1},
title = {{Explainable Artificial Intelligence Research at DARPA}},
url = {https://sites.nationalacademies.org/cs/groups/pgasite/documents/webpage/pga{\_}184754.pdf}
}

@techreport{ainow2018,
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - LITIGATING ALGORITHMS CHALLENGING GOVERNMENT USE OF ALGORITHMIC DECISION SYSTEMS.pdf:pdf},
mendeley-groups = {2.XAI-2},
title = {{LITIGATING ALGORITHMS: CHALLENGING GOVERNMENT USE OF ALGORITHMIC DECISION SYSTEMS}},
url = {https://ainowinstitute.org/litigatingalgorithms.pdf}
}

@book{gerrish_how_2018,
Address = {Cambridge, MA},
Author = {Gerrish, Sean author},
Publisher = {The MIT Press},
Title = {How smart machines think}}
	
@article{shannon_mattern,
author = {Mattern, Shannon},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Mapping's Intelligent Agents{\_} Autonomous Cars and Beyond.pdf:pdf},
journal = {Places},
keywords = {SHANNON MATTERN},
mendeley-groups = {1.PRIORITY-1},
title = {{Mapping's intelligent agents: Autonomous cars and beyond}},
year = {2017}
}

@article{Liu2017,
abstract = {Interactive model analysis, the process of understanding, diagnosing, and refining a machine learning model with the help of interactive visualization, is very important for users to efficiently solve real-world artificial intelligence and data mining problems. Dramatic advances in big data analytics have led to a wide variety of interactive model analysis tasks. In this paper, we present a comprehensive analysis and interpretation of this rapidly developing area. Specifically, we classify the relevant work into three categories: understanding, diagnosis, and refinement. Each category is exemplified by recent influential work. Possible future research opportunities are also explored and discussed.},
author = {Liu, Shixia and Wang, Xiting and Liu, Mengchen and Zhu, Jun},
doi = {10.1016/J.VISINF.2017.01.006},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2017 - Towards better analysis of machine learning models A visual analytics perspective.pdf:pdf},
issn = {2468-502X},
journal = {Visual Informatics},
mendeley-groups = {1.PRIORITY-1},
month = {mar},
number = {1},
pages = {48--56},
publisher = {Elsevier},
title = {{Towards better analysis of machine learning models: A visual analytics perspective}},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X17300086},
volume = {1},
year = {2017}
}

@article{Sacha2017,
abstract = {Visual analytics (VA) systems help data analysts solve complex problems interactively, by integrating automated data analysis and mining, such as machine learning (ML) based methods, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and that puts the central relationship between automated algorithms and interactive visualizations into sharp focus. The framework is illustrated with several examples and we further elaborate on the interactive ML process by identifying key scenarios where ML methods are combined with human feedback through interactive visualization. We derive five open research challenges at the intersection of ML and visualization research, whose solution should lead to more effective data analysis.},
author = {Sacha, Dominik and Sedlmair, Michael and Zhang, Leishi and Lee, John A. and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C. and Keim, Daniel A.},
doi = {10.1016/J.NEUCOM.2017.01.105},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Sacha et al. - 2017 - What you see is what you can change Human-centered machine learning by interactive visualization(2).pdf:pdf},
issn = {0925-2312},
journal = {Neurocomputing},
mendeley-groups = {1.PRIORITY-2},
month = {dec},
pages = {164--175},
publisher = {Elsevier},
title = {{What you see is what you can change: Human-centered machine learning by interactive visualization}},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217307609},
volume = {268},
year = {2017}
}

@article{dl_evolution,
abstract = {This paper historically attempts to map the significant success of deep neural networks in notably varied classification problems and application domains with near human-level performance. The paper also addresses the various doubts surrounding the acceptance of deep learning as a science of future. The manuscript attempts to unveil the hidden capabilities of deep neural networks in enabling machines perform the human way tasks which can be learned through what we call observation and experience.},
author = {Wason, Ritika},
doi = {10.1016/j.cogsys.2018.08.023},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Wason - 2018 - Deep learning Evolution and expansion(2).pdf:pdf},
keywords = {Deep learning,Multi-layer neural networks},
mendeley-groups = {1.PRIORITY-2},
title = {{Deep learning: Evolution and expansion}},
url = {https://doi.org/10.1016/j.cogsys.2018.08.023},
year = {2018}
}

@techreport{Zeiler,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark (Krizhevsky et al., 2012). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architec-tures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
archivePrefix = {arXiv},
arxivId = {1311.2901v3},
author = {Zeiler, Matthew D and Fergus, Rob},
eprint = {1311.2901v3},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Zeiler, Fergus - Unknown - Visualizing and Understanding Convolutional Networks.pdf:pdf},
mendeley-groups = {1.PRIORITY-2},
title = {{Visualizing and Understanding Convolutional Networks}},
url = {https://arxiv.org/pdf/1311.2901.pdf}
}

@techreport{pavlus_john,
abstract = {On a quest to demystify deep learning, Tomaso Poggio glimpses tantalizing implications for human intelligence},
author = {Pavlus, John},
file = {:Users/parvezahmedkose/Library/Application Support/Mendeley Desktop/Downloaded/Pavlus - 2018 - Plumbing the Depths of Neural Nets.pdf:pdf},
mendeley-groups = {Journal-Articles},
title = {{Plumbing the Depths of Neural Nets}},
year = {2018}
}
